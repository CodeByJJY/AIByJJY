from sklearn.model_selection import cross_val_score   # scikit-learn 라이브러리에서 제공하느 cross_val_score 함수를 사용하겠다.

## K-fold Cross-validation
# 1) 데이터 분할 : 데이터를 K개의 동일한 크기의 파트(fold)로 나눈다.
# 2) 교차 검증 반복 :
#    - 각 반복에서, 하나의 fold를 validation set, 나머지 (K-1)개의 fold를 training set로 사용.
#    - K번의 반복을 통해, 모든 fold가 한 번씩 데이터로 사용된다.
# 3) 평균 성능 계산 : 각 반복에서 평가된 성능(예:accuracy)을 기록하고, 그 성능을 평균내어 최종 모델의 성능 평가.

## SGD(Stochastic Gradient Descent, 확률적 경사 하강법)
# 기본 개념 : 무작위로 선택된 한 개의 샘플(또는 작은 mini batch)만을 사용하여 그래디언트를 계산한다.
# 1) 무작위 샘플 선택
# 2) 그래디언트 계산
# 3) 파라미터 업데이트

cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring="accuracy")
# cross_val_score 함수 : K-fold cross-validation 수행.
# sgd_clf : SGDClassifier. estimator의 종류 중 하나이다.
# X_train : 훈련에 사용할 데이터(features).
# y_train_5 : 각 데이터 샘플에 해당하는 label.
# cv = 3 : 3겹 교차 검증. 데이터를 3개의 subset으로 나누고, 각 subset을 테스트 데이터로 사용하여 3번의 validation 진행.
# scoring = "accuracy" : 모델 성능을 평가할 때 사용할 기준이 accuracy(정확도)임을 나타낸다.

from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone

## StratifiedKFold(n_splits=3)
#   - StratifiedKFold : 데이터를 단순히 무작위로 나누는 것이 아니라,
#                       각 클래스의 비율을 유지한 채로 데이터를 K개의 fold으로 나눔.
#                       ex) data set 구성이 (클래스 A 90%)+(클래스 B 10%) -> 각 fold에서도 클래스별 비율 유
skfolds = StratifiedKFold(n_splits=3)

# for문을 통해 X_train과 y_train_5를 3개의 fold으로 나눔.
for train_index, test_index in skfolds.split(X_train, y_train_5):
  clone_clf = clone(sgd_clf)              # sgd_clf의 동일한 사본을 만들어 저장.
  # X_train_folds, y_train_folds : 현재 반복에서 훈련 데이터로 사용할 부분을 의미.
  #                                train_index를 사용하여 원본 데이터에서 추출함.
  X_train_folds = X_train[train_index]
  y_train_folds = y_train_5[train_index]
  # X_train_folds, y_train_folds : 현재 반복에서 테스트 데이터로 사용할 부분을 의미.
  X_test_fold = X_train[test_index]
  y_test_fold = y_train_5[test_index]

  # clone_clf.fit() : SGDClassifier를 현재 fold에서의 train data로 학습.
  clone_clf.fit(X_train_folds, y_train_folds)
  # clone_clf.predict() : training을 수행한 SGDClassifier(Model)에 test fold data를 입력하여 예측 수행.
  y_pred = clone_clf.predict(X_test_fold)
  # n_correct : 예측 결과(y_pred)가 실제 정답(y_test_fold)과 일치하는 항목의 수를 계산.
  n_correct = sum(y_pred == y_test_fold)
  # accuracy = n_correct(정답 개수) / y_pred(테스트 데이터 총 개수)
  print(n_correct / len(y_pred))





from sklearn.dummy import DummyClassifier

##  DummyClassifier
#   : 매우 단순한 모델. 주어진 데이터에 대해 의미 있는 학습을 하지 않는다.
#    대신 무작위 추정이나 특정 규칙(예: 클래스 비율에 따른 예측)을 기반으로 예측을 진행한다.
dummy_clf = DummyClassifier()
## fit()
#  원래는 모델을 훈련시키는 단계.
#  DummyClassifier는 실제로 학습을 수행하지 않으며, 단지 데이터를 분석해 특정 예측 전략(예: 가장 빈번한 클래스)을 따른다.
dummy_clf.fit(X_train, y_train_5)
## any()
#  예측 결과 중 하나라도 참(True) 값이 있는지 확인하는 함수.
## dummy_clf.predict() : train data에 대해 예측한 결과를 반환.
print(any(dummy_clf.predict(X_train)))

# DummyClassifier 모델이 3-folds cross-validation에서 각 fold에 대해 얼마나 높은 정확도를 보이는지 평가.
cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring="accuracy")
